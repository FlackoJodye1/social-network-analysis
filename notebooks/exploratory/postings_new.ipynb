{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POSTINGS NETWORK\n",
    "The following notebook contains the code used for obtaining assortative mixing coefficients for the network built using posting's replies as edges. In particular:\n",
    "- users are the nodes\n",
    "- an edge is created if one node (source) replies to the posting of another user (target)\n",
    "We are building a directed and weighted network, in which weights are given by the number of times a source replied to a target node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"../../data/raw/\")\n",
    "filename_first = \"Postings_01052019_15052019.csv\"\n",
    "filename_second = \"Postings_16052019_31052019.csv\"\n",
    "\n",
    "# use this output-path for saving figures\n",
    "FIG_OUTPUT_PATH = Path(\"../../reports/figures/postings/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..\\\\..\\\\data\\\\raw\\\\Postings_01052019_15052019.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m postings1_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_DIR\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfilename_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m;\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m postings2_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(DATA_DIR \u001b[38;5;241m/\u001b[39m filename_second, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\maria\\anaconda3\\envs\\SNA_env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\maria\\anaconda3\\envs\\SNA_env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\maria\\anaconda3\\envs\\SNA_env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\maria\\anaconda3\\envs\\SNA_env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\maria\\anaconda3\\envs\\SNA_env\\lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '..\\\\..\\\\data\\\\raw\\\\Postings_01052019_15052019.csv'"
     ]
    }
   ],
   "source": [
    "postings1_df = pd.read_csv(DATA_DIR / filename_first, sep=';', dtype=str)\n",
    "postings2_df = pd.read_csv(DATA_DIR / filename_second, sep=';', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data about all postings in the period 01.05.2019 - 31.05.2019\n",
    "postings1_df = pd.read_csv('Postings_01052019_15052019.csv', sep=';')\n",
    "postings2_df = pd.read_csv('Postings_16052019_31052019.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_Posting</th>\n",
       "      <th>ID_Posting_Parent</th>\n",
       "      <th>ID_CommunityIdentity</th>\n",
       "      <th>PostingHeadline</th>\n",
       "      <th>PostingComment</th>\n",
       "      <th>PostingCreatedAt</th>\n",
       "      <th>ID_Article</th>\n",
       "      <th>ArticlePublishingDate</th>\n",
       "      <th>ArticleTitle</th>\n",
       "      <th>ArticleChannel</th>\n",
       "      <th>ArticleRessortName</th>\n",
       "      <th>UserCommunityName</th>\n",
       "      <th>UserGender</th>\n",
       "      <th>AccountAge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1041073586</td>\n",
       "      <td>1.041073e+09</td>\n",
       "      <td>671476</td>\n",
       "      <td>Das hat gestern bereits der Voggenhuber angefü...</td>\n",
       "      <td>schieder hatte dem inhaltlich nichts entgegenz...</td>\n",
       "      <td>2019-05-01 18:21:15.127</td>\n",
       "      <td>2000102330973</td>\n",
       "      <td>2019-05-01 10:28:57.49</td>\n",
       "      <td>1. Mai in Wien: SPÖ fordert von Strache Rücktritt</td>\n",
       "      <td>Inland</td>\n",
       "      <td>Parteien</td>\n",
       "      <td>Ravenspower</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1041073839</td>\n",
       "      <td>1.041073e+09</td>\n",
       "      <td>566938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...und meinen Bezirk bekommst du als Erbe mit.</td>\n",
       "      <td>2019-05-01 18:28:22.040</td>\n",
       "      <td>2000102330973</td>\n",
       "      <td>2019-05-01 10:28:57.49</td>\n",
       "      <td>1. Mai in Wien: SPÖ fordert von Strache Rücktritt</td>\n",
       "      <td>Inland</td>\n",
       "      <td>Parteien</td>\n",
       "      <td>AlphaRomeo</td>\n",
       "      <td>m</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1041073872</td>\n",
       "      <td>1.041069e+09</td>\n",
       "      <td>669286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nein, bei der ÖVP/FPÖ genauso passiert. Ich wo...</td>\n",
       "      <td>2019-05-01 18:29:05.533</td>\n",
       "      <td>2000102330973</td>\n",
       "      <td>2019-05-01 10:28:57.49</td>\n",
       "      <td>1. Mai in Wien: SPÖ fordert von Strache Rücktritt</td>\n",
       "      <td>Inland</td>\n",
       "      <td>Parteien</td>\n",
       "      <td>Hpolditsch</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1041080734</td>\n",
       "      <td>1.041080e+09</td>\n",
       "      <td>671476</td>\n",
       "      <td>Sie haben doch nichts gefordert??</td>\n",
       "      <td>sie haben nur die regierung kritisiert. das di...</td>\n",
       "      <td>2019-05-01 22:37:56.010</td>\n",
       "      <td>2000102330973</td>\n",
       "      <td>2019-05-01 10:28:57.49</td>\n",
       "      <td>1. Mai in Wien: SPÖ fordert von Strache Rücktritt</td>\n",
       "      <td>Inland</td>\n",
       "      <td>Parteien</td>\n",
       "      <td>Ravenspower</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1041080828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>671476</td>\n",
       "      <td>Heute wäre der perfekte Tag für die SPÖ gewese...</td>\n",
       "      <td>ihr noch nicht erfülltes versprechen, den silb...</td>\n",
       "      <td>2019-05-01 22:42:06.310</td>\n",
       "      <td>2000102330973</td>\n",
       "      <td>2019-05-01 10:28:57.49</td>\n",
       "      <td>1. Mai in Wien: SPÖ fordert von Strache Rücktritt</td>\n",
       "      <td>Inland</td>\n",
       "      <td>Parteien</td>\n",
       "      <td>Ravenspower</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_Posting  ID_Posting_Parent  ID_CommunityIdentity  \\\n",
       "0  1041073586       1.041073e+09                671476   \n",
       "1  1041073839       1.041073e+09                566938   \n",
       "2  1041073872       1.041069e+09                669286   \n",
       "3  1041080734       1.041080e+09                671476   \n",
       "4  1041080828                NaN                671476   \n",
       "\n",
       "                                     PostingHeadline  \\\n",
       "0  Das hat gestern bereits der Voggenhuber angefü...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                  Sie haben doch nichts gefordert??   \n",
       "4  Heute wäre der perfekte Tag für die SPÖ gewese...   \n",
       "\n",
       "                                      PostingComment         PostingCreatedAt  \\\n",
       "0  schieder hatte dem inhaltlich nichts entgegenz...  2019-05-01 18:21:15.127   \n",
       "1     ...und meinen Bezirk bekommst du als Erbe mit.  2019-05-01 18:28:22.040   \n",
       "2  Nein, bei der ÖVP/FPÖ genauso passiert. Ich wo...  2019-05-01 18:29:05.533   \n",
       "3  sie haben nur die regierung kritisiert. das di...  2019-05-01 22:37:56.010   \n",
       "4  ihr noch nicht erfülltes versprechen, den silb...  2019-05-01 22:42:06.310   \n",
       "\n",
       "      ID_Article   ArticlePublishingDate  \\\n",
       "0  2000102330973  2019-05-01 10:28:57.49   \n",
       "1  2000102330973  2019-05-01 10:28:57.49   \n",
       "2  2000102330973  2019-05-01 10:28:57.49   \n",
       "3  2000102330973  2019-05-01 10:28:57.49   \n",
       "4  2000102330973  2019-05-01 10:28:57.49   \n",
       "\n",
       "                                        ArticleTitle ArticleChannel  \\\n",
       "0  1. Mai in Wien: SPÖ fordert von Strache Rücktritt         Inland   \n",
       "1  1. Mai in Wien: SPÖ fordert von Strache Rücktritt         Inland   \n",
       "2  1. Mai in Wien: SPÖ fordert von Strache Rücktritt         Inland   \n",
       "3  1. Mai in Wien: SPÖ fordert von Strache Rücktritt         Inland   \n",
       "4  1. Mai in Wien: SPÖ fordert von Strache Rücktritt         Inland   \n",
       "\n",
       "  ArticleRessortName UserCommunityName UserGender  AccountAge  \n",
       "0           Parteien       Ravenspower        NaN           6  \n",
       "1           Parteien        AlphaRomeo          m           9  \n",
       "2           Parteien        Hpolditsch        NaN           6  \n",
       "3           Parteien       Ravenspower        NaN           6  \n",
       "4           Parteien       Ravenspower        NaN           6  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a unique dataframe\n",
    "postings_df = pd.concat([postings1_df, postings2_df])\n",
    "\n",
    "# Convert the creation date of the account to the \"age\" of the account\n",
    "postings_df['UserCreatedAt'] = 2024 - (pd.to_datetime(postings_df['UserCreatedAt']).dt.year)\n",
    "postings_df = postings_df.rename(columns={'UserCreatedAt': 'AccountAge'})\n",
    "\n",
    "postings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "739094\n",
      "23925\n"
     ]
    }
   ],
   "source": [
    "# Let us see how many unique users we have in the dataset - they will be the nodes of the networks\n",
    "print(len(postings_df))\n",
    "print(len(postings_df['ID_CommunityIdentity'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nodes attributes\n",
    "Now we create a separate dataframe in which we store the attributes for each user in the blog - they will be the attributes of each node in the networks. \n",
    "\n",
    "For this analysis we are interested in:\n",
    "- gender of the user\n",
    "- age of the account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CommunityIdentity</th>\n",
       "      <th>UserGender</th>\n",
       "      <th>AccountAge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>671476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>566938</td>\n",
       "      <td>m</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>669286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>523527</td>\n",
       "      <td>m</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>74674</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_CommunityIdentity UserGender  AccountAge\n",
       "0                671476        NaN           6\n",
       "1                566938          m           9\n",
       "2                669286        NaN           6\n",
       "6                523527          m          11\n",
       "7                 74674        NaN          17"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract nodes attributes and store them in a pandas df - assuming that one node is a user\n",
    "df_attributes = postings_df[['ID_CommunityIdentity', 'UserGender', 'AccountAge']].drop_duplicates()\n",
    "len(df_attributes)\n",
    "df_attributes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter data according to the Article Channel\n",
    "Due to high amount of data, we decided to measure the assortative mixing coefficients for some subgroups. To do so, data is split according to the article channel of the post and a dictionary of datasets is created to store all the different data related to each topic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Inland' 'Meinung' 'International' 'Sport' 'Panorama' 'Wirtschaft'\n",
      " 'Gesundheit' 'Web' 'Kultur' 'Bildung' 'Wissenschaft' 'Immobilien' 'User'\n",
      " 'dieStandard' 'Etat' 'Zukunft' 'Karriere' 'Lifestyle' 'Diverses' 'Reisen'\n",
      " 'AutoMobil' 'Familie']\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "# Get the list of unique channels\n",
    "channels = postings_df['ArticleChannel'].unique()\n",
    "\n",
    "print(channels)\n",
    "print(len(channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Parteien' 'Sachpolitik' 'SPÖ' 'Sozialpolitik & Armut' 'Inland'\n",
      " 'Heer & Zivildienst' 'Niederösterreich' 'Neos' 'Rechtsextremismus' 'ÖVP'\n",
      " 'Nationalsozialismus' 'Koalition' 'Gesundheitspolitik'\n",
      " 'Religion & Politik' 'Österreich und EU' 'Parlament' 'Tirol' 'FPÖ'\n",
      " 'Integrationspolitik' 'Oberösterreich' 'Salzburg' 'Phänomen Hass'\n",
      " 'Pensionen' 'Öffentlicher Dienst' 'Staat & Justiz' 'Bundespräsident'\n",
      " 'Standardabweichung' 'Grüne' 'Verfassungsschutz' 'Nationalrat'\n",
      " 'Liste Jetzt' 'Kärnten' 'Bundesländer' 'Sicherheitspolitik' 'Eurofighter'\n",
      " 'Burgenland' 'Wiener Politik' 'Vorarlberg' 'Kulturpolitik'\n",
      " 'Lobbying & Korruption' 'Politische Umfragen'\n",
      " 'Blog: Stadt, Land, Politik'\n",
      " 'EU-Wahl 2019 in Österreich: Wahlergebnisse und -gr'\n",
      " 'Nationalratswahl 2017']\n",
      "44\n"
     ]
    }
   ],
   "source": [
    "# Get the list of unique sub_channels for Inland\n",
    "sub_channels = postings_df[postings_df['ArticleChannel'] == 'Inland']['ArticleRessortName'].unique()\n",
    "\n",
    "print(sub_channels)\n",
    "print(len(sub_channels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Article channels can be further divided into more specific sub-channels. Given that most of the topics related to the \"Inland\" channel deal with internal politics, we decided to use data coming from the \"Inland\" df to study homophily of the user in the political field. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the DataFrame by the 'ArticleChannel' column\n",
    "grouped_df = postings_df.groupby('ArticleChannel')\n",
    "\n",
    "# Create a dictionary to store DataFrames based on ArticleChannel\n",
    "channel_dfs = {}\n",
    "\n",
    "# Iterate through the grouped DataFrame and create individual DataFrames\n",
    "for channel, channel_group in grouped_df:\n",
    "    channel_dfs[channel] = channel_group.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame for AutoMobil: (6366, 14)\n",
      "Shape of DataFrame for Bildung: (7942, 14)\n",
      "Shape of DataFrame for Diverses: (4597, 14)\n",
      "Shape of DataFrame for Etat: (34890, 14)\n",
      "Shape of DataFrame for Familie: (2658, 14)\n",
      "Shape of DataFrame for Gesundheit: (10490, 14)\n",
      "Shape of DataFrame for Immobilien: (5071, 14)\n",
      "Shape of DataFrame for Inland: (188069, 14)\n",
      "Shape of DataFrame for International: (55911, 14)\n",
      "Shape of DataFrame for Karriere: (2459, 14)\n",
      "Shape of DataFrame for Kultur: (24013, 14)\n",
      "Shape of DataFrame for Lifestyle: (11124, 14)\n",
      "Shape of DataFrame for Meinung: (96008, 14)\n",
      "Shape of DataFrame for Panorama: (98391, 14)\n",
      "Shape of DataFrame for Reisen: (3285, 14)\n",
      "Shape of DataFrame for Sport: (40396, 14)\n",
      "Shape of DataFrame for User: (12760, 14)\n",
      "Shape of DataFrame for Web: (59589, 14)\n",
      "Shape of DataFrame for Wirtschaft: (50755, 14)\n",
      "Shape of DataFrame for Wissenschaft: (12565, 14)\n",
      "Shape of DataFrame for Zukunft: (4228, 14)\n",
      "Shape of DataFrame for dieStandard: (7527, 14)\n"
     ]
    }
   ],
   "source": [
    "#Print the shape of each DataFrame - to obtain information about the lenght \n",
    "for channel, df in channel_dfs.items():\n",
    "    print(f\"Shape of DataFrame for {channel}: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We focused only on a subset of channels, namely\n",
    "- Sport\n",
    "- Economy\n",
    "- Culture\n",
    "- Education\n",
    "- Career\n",
    "- Family\n",
    "- Inland (for politics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider only a subset of DataFrame in the dictionary\n",
    "selected_channels = ['Wirtschaft', 'Sport', 'Kultur', 'Bildung', 'Karriere', 'Familie', 'Inland']\n",
    "filtered_dict = {k: v for k, v in channel_dfs.items() if k in selected_channels}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the networks\n",
    "For each DataFrame in filtered_dict, we create a weighted networks (with characteristics stated above). We store the networks in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Disclaimer: this cell is rather slow\n",
    "\n",
    "# Create dictionaries to store edge lists and weighted edge lists\n",
    "edge_lists = {}\n",
    "weighted_edge_lists = {}\n",
    "\n",
    "# Create a dictionary to store df containing source (repliyng user), target (replied user) and weight (number of replies)\n",
    "edges_dfs = {} \n",
    "\n",
    "### Obtain edge list and df for each DataFrames in filtered_dict\n",
    "for channel, df in filtered_dict.items():\n",
    "    # Obtain the list of edges for the current DataFrame\n",
    "    edgeList = [\n",
    "        [post.ID_CommunityIdentity, next(iter(df[df.ID_Posting == post.ID_Posting_Parent].ID_CommunityIdentity))]\n",
    "        for idx, post in df.iterrows()\n",
    "        if not pd.isna(post.ID_Posting_Parent)\n",
    "    ]\n",
    "\n",
    "    # Obtain the weights for the edges\n",
    "    weightedEdgeList = [(edge[0], edge[1], edgeList.count(edge)) for edge in edgeList]\n",
    "    weightedEdgeList = list(set(weightedEdgeList))\n",
    "\n",
    "    # Store the lists for each DataFrame in the dictionaries\n",
    "    edge_lists[channel] = edgeList\n",
    "    weighted_edge_lists[channel] = weightedEdgeList\n",
    "\n",
    "    # Create a DataFrame for the current list of edges\n",
    "    edges_df = pd.DataFrame(weightedEdgeList, columns=['source', 'target', 'weight'])         # needed for creating the network\n",
    "    edges_dfs[channel] = edges_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and store a graph for each DataFrame in edges_df\n",
    "graphs = {}\n",
    "for channel_name, df in edges_dfs.items():\n",
    "    G = nx.from_pandas_edgelist(df, 'source', 'target', edge_attr='weight', create_using=nx.DiGraph())\n",
    "\n",
    "    # account for missing values, using the attributes df created before\n",
    "    for _, row in df_attributes.iterrows():\n",
    "        if row['ID_CommunityIdentity'] in G:\n",
    "            if row['UserGender'] in ['m', 'f'] and row['AccountAge'] > 0:        # no missing values should occur in the AccountAge variable\n",
    "                nx.set_node_attributes(G, {row['ID_CommunityIdentity']: row['UserGender']}, 'gender')\n",
    "                nx.set_node_attributes(G, {row['ID_CommunityIdentity']: row['AccountAge']}, 'age')\n",
    "    \n",
    "    graphs[channel_name] = G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "According to the obtained results, assortative mixing behaviour cannot be observe for none of the considered features as values are very close to zero for all attributes in all article channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel: Bildung\n",
      "Assortative Mixing by Gender: 0.0387\n",
      "Assortative Mixing by Age: 0.0306\n",
      "Assortive mixing by degree: 0.0319\n",
      "------------------------------------------------------\n",
      "Channel: Familie\n",
      "Assortative Mixing by Gender: -0.0164\n",
      "Assortative Mixing by Age: 0.0032\n",
      "Assortive mixing by degree: 0.1127\n",
      "------------------------------------------------------\n",
      "Channel: Inland\n",
      "Assortative Mixing by Gender: 0.0137\n",
      "Assortative Mixing by Age: 0.0120\n",
      "Assortive mixing by degree: -0.0114\n",
      "------------------------------------------------------\n",
      "Channel: Karriere\n",
      "Assortative Mixing by Gender: 0.0365\n",
      "Assortative Mixing by Age: 0.0193\n",
      "Assortive mixing by degree: 0.0990\n",
      "------------------------------------------------------\n",
      "Channel: Kultur\n",
      "Assortative Mixing by Gender: 0.0394\n",
      "Assortative Mixing by Age: 0.0220\n",
      "Assortive mixing by degree: -0.0099\n",
      "------------------------------------------------------\n",
      "Channel: Sport\n",
      "Assortative Mixing by Gender: 0.0228\n",
      "Assortative Mixing by Age: 0.0144\n",
      "Assortive mixing by degree: 0.0005\n",
      "------------------------------------------------------\n",
      "Channel: Wirtschaft\n",
      "Assortative Mixing by Gender: 0.0190\n",
      "Assortative Mixing by Age: 0.0141\n",
      "Assortive mixing by degree: -0.0021\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the dictionary of graphs\n",
    "for channel, G in graphs.items():\n",
    "    # Compute assortative mixing gender and age and node degree\n",
    "    assortativity_gender = nx.attribute_assortativity_coefficient(G, attribute='gender')\n",
    "    assortativity_age = nx.attribute_assortativity_coefficient(G, attribute='age')\n",
    "    degree_assortativity = nx.degree_assortativity_coefficient(G, x='in', y='in', weight='weight')\n",
    "\n",
    "    # Print results with channel name\n",
    "    print(f\"Channel: {channel}\")\n",
    "    print(f\"Assortative Mixing by Gender: {assortativity_gender:.4f}\")\n",
    "    print(f\"Assortative Mixing by Age: {assortativity_age:.4f}\")\n",
    "    print(f\"Assortive mixing by degree: {degree_assortativity:.4f}\")\n",
    "    print('------------------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SNA_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
